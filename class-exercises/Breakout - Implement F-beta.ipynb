{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "734b5c82",
   "metadata": {},
   "source": [
    "# Breakout - Implement F-beta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db29bfe8",
   "metadata": {},
   "source": [
    "When Î²=1, the F-beta score becomes the harmonic mean of precision and recall, which is commonly known as the F1 score. The F1 score equally weights precision and recall, making it a balanced measure of a model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e9ec42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f1_score(precision, recall):\n",
    "    return 2 * (precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b323e661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.7466666666666666\n"
     ]
    }
   ],
   "source": [
    "# Example precision and recall values\n",
    "precision = 0.8\n",
    "recall = 0.7\n",
    "\n",
    "f_1_score = calculate_f1_score(precision, recall)\n",
    "print(f\"F1 Score:\", f_1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71b3e87",
   "metadata": {},
   "source": [
    "In this example:\n",
    "\n",
    "* We define a function calculate_f_beta_score to compute the F-beta score given precision, recall, and the beta value.\n",
    "* We set example precision and recall values.\n",
    "* We define a list of beta values [0.5, 1, 2].\n",
    "* We loop through the beta values, calculate the corresponding F-beta score using the function, and print the results.\n",
    "\n",
    "The output will show the F-beta scores for each beta value:\n",
    "```\n",
    "F0.5 Score: 0.7777777777777778\n",
    "F1 Score: 0.7466666666666666\n",
    "F2 Score: 0.7179487179487178\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aaf398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f_beta_score(precision, recall, beta):\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44826919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F0.5 Score: 0.7777777777777778\n",
      "F1 Score: 0.7466666666666666\n",
      "F2 Score: 0.7179487179487178\n"
     ]
    }
   ],
   "source": [
    "# Example precision and recall values\n",
    "precision = 0.8\n",
    "recall = 0.7\n",
    "\n",
    "# Varying beta values\n",
    "beta_values = [0.5, 1, 2]\n",
    "\n",
    "# Calculate F-beta scores for each beta value\n",
    "for beta in beta_values:\n",
    "    f_beta_score = calculate_f_beta_score(precision, recall, beta)\n",
    "    print(f\"F{beta} Score:\", f_beta_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bee33c",
   "metadata": {},
   "source": [
    "The significance of the results relative to the input beta values lies in understanding how different emphasis on precision versus recall affects the F-beta score.\n",
    "\n",
    "1. When Beta = 0.5:\n",
    "* A lower beta value (e.g., 0.5) emphasizes precision more than recall in the F-beta score calculation.\n",
    "* In this scenario, the model's performance is evaluated with a greater focus on minimizing false positives.\n",
    "* A higher F-beta score indicates that the model has a good balance between precision and recall, but precision is given slightly more weight.\n",
    "\n",
    "2. When Beta = 1 (F1 Score):\n",
    "* When beta equals 1, we calculate the F1 score, which equally weights precision and recall.\n",
    "* The F1 score provides a balanced measure of the model's performance, considering both false positives and false negatives.\n",
    "* It is commonly used in binary classification tasks where precision and recall are of equal importance.\n",
    "\n",
    "3. When Beta = 2:\n",
    "* A higher beta value (e.g., 2) emphasizes recall more than precision in the F-beta score calculation.\n",
    "* In this case, the model's performance is evaluated with a greater focus on minimizing false negatives.\n",
    "* A higher F-beta score indicates that the model is better at capturing true positives, but it may come at the expense of higher false positives.\n",
    "\n",
    "\n",
    "By varying the beta value, we can adjust the relative importance of precision and recall based on the specific requirements of the application. This allows for a more nuanced evaluation of the model's performance, enabling stakeholders to make informed decisions based on their priorities and goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a2ccad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
